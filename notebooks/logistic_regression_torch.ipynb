{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('./pytorch_models')\n",
    "import os \n",
    "\n",
    "os.environ['PYTHONDONTWRITEBYTECODE'] ='1'\n",
    "sys.path.append('../')\n",
    "#sys.path.append('../torch_ml')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from torch_ml.models.pytorch_clf import *\n",
    "import torch \n",
    "from datasets import dataset_factory\n",
    "from utils.logging_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger('./logs/log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {}\n",
    "data_conf = {'dataset':'unif_unit_ball','n_samples':1500, 'dimension':2,'test_size':500,'random_state':0,'tensorize':True}\n",
    "model_conf = {'model_name':'binary_logistic_regression','input_dimension':2,'num_classes':2,'fit_intercept':False}\n",
    "training_conf = {'optimizer':'sgd','learning_rate':1e-2,'batch_size':32}\n",
    "inference_conf = {'batch_size':64}\n",
    "\n",
    "conf['data_conf'] = data_conf\n",
    "conf['model_conf'] = model_conf \n",
    "conf['training_conf'] = training_conf\n",
    "conf['inference_conf'] = inference_conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_unit_ball_dataset = dataset_factory.load_dataset(conf)\n",
    "unif_unit_ball_dataset.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013154310882091522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = PyTorchClassifier(conf['model_conf'],logger=logger)\n",
    "lr_model.fit(unif_unit_ball_dataset.train_dataset,training_conf=conf['training_conf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat, P_hat = lr_model.predict(unif_unit_ball_dataset.test_dataset,conf['inference_conf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9940)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_score(Y,Y_hat):\n",
    "    return (Y.eq(Y_hat)).sum()/len(Y)\n",
    "accuracy_score(unif_unit_ball_dataset.test_dataset.targets, Y_hat) \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "140760a31b56e8a3c5592d32072d5d912b2d41de7a4e4038746bf646420bd276"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
